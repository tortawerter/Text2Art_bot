import torch
from diffusers import StableDiffusionPipeline
from telebot import types, telebot
import os
from dotenv import load_dotenv
import re
import queue
import threading
import time


messages = [
    "üëã –ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! –≠—Ç–æ Text2ART - –±–æ—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –ø–æ —Ç–µ–∫—Å—Ç–æ–≤–æ–º—É –∑–∞–ø—Ä–æ—Å—É\n"  # 0
    "\n"
    "–î–∞–≤–∞–π—Ç–µ –ø–æ–ø—Ä–æ–±—É–µ–º —á—Ç–æ-–Ω–∏–±—É–¥—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å. –î–ª—è –Ω–∞—á–∞–ª–∞ –≤—ã–±–µ—Ä–∏—Ç–µ, –≤ –∫–∞–∫–æ–º —Å—Ç–∏–ª–µ –í—ã —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ",

    "–ü–æ –≤—Å–µ–º –≤–æ–ø—Ä–æ—Å–∞–º –∏–ª–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è–º –í—ã –º–æ–∂–µ—Ç–µ –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ü–∏–∏ –±–æ—Ç–∞\n"  # 1
    "\n"
    "~@Chedrok\n"
    "~@Dust_mi",

    "üîß –¢–µ–ø–µ—Ä—å —É–∫–∞–∂–∏—Ç–µ —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è\n"  # 2
    "(–±–æ–ª—å—à–µ —à–∞–≥–æ–≤ -> –ø—Ä–æ—Ä–∞–±–æ—Ç–∞–Ω–Ω–µ–µ, –º–µ–¥–ª–µ–Ω–Ω–µ–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)",

    "–í—ã–±–µ—Ä–∏—Ç–µ —Ñ–æ—Ä–º–∞—Ç –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è:"  # 3
]


load_dotenv()
token = os.getenv('TOKEN')

style = ""
model_id = ""
sampling_steps = 0
user_prompt = ""
height = 0
width = 0

bot = telebot.TeleBot(token)

request_queue = queue.Queue()
processing_queue = False


@bot.message_handler(commands=['start'])
def start_message(message):
    markup = types.InlineKeyboardMarkup()

    btn1 = types.InlineKeyboardButton(
        text="üåÑ –†–µ–∞–ª–∏–∑–º",
        callback_data="–†–µ–∞–ª–∏–∑–º"
    )

    btn2 = types.InlineKeyboardButton(
        text="üñåÔ∏è –†–∏—Å—É–Ω–æ–∫",
        callback_data="—Ä–∏—Å—É–Ω–æ–∫"
    )

    btn3 = types.InlineKeyboardButton(
        text="–ü–æ–º–æ—â—å/–ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è",
        callback_data="–ø–æ–º–æ—â—å"
    )

    markup.add(btn1)
    markup.add(btn2)
    markup.add(btn3)

    bot.send_message(message.from_user.id,
                     text=messages[0], reply_markup=markup)


@bot.callback_query_handler(func=lambda call: True)
def inline_start_btn(call):
    global model_id, sampling_steps, width, height

    if call.data == "–ø–æ–º–æ—â—å":
        bot.send_message(call.message.chat.id, messages[1])

    elif call.data == "–†–µ–∞–ª–∏–∑–º":
        model_id = "SG161222/Realistic_Vision_V5.0_noVAE"
        bot.send_message(call.message.chat.id, "–ß—Ç–æ –í—ã —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å?\n"
                         "‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –∞–ª—Ñ–∞–≤–∏—Ç–∞\n"
                         "\n"
                         "‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ NSFW –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        bot.register_next_step_handler(call.message, get_prompt)

    elif call.data == "—Ä–∏—Å—É–Ω–æ–∫":
        model_id = "dreamlike-art/dreamlike-anime-1.0"
        bot.send_message(call.message.chat.id, "–ß—Ç–æ –í—ã —Ö–æ—Ç–∏—Ç–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å?\n"
                         "‚úÖ –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –∞–ª—Ñ–∞–≤–∏—Ç–∞\n"
                         "\n"
                         "‚ùå –ü—Ä–∏ –ø–æ–ø—ã—Ç–∫–µ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ NSFW –∫–æ–Ω—Ç–µ–Ω—Ç–∞ –±—É–¥–µ—Ç –æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–æ –ø—É—Å—Ç–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ")
        bot.register_next_step_handler(call.message, get_prompt)

    elif call.data in ["20", "50", "75", "100"]:
        sampling_steps = int(call.data)
        scale(call)

    elif call.data == "vert":
        width = 512
        height = 912
        model_name = "—Ä–∏—Å—É–Ω–æ–∫" if model_id == "dreamlike-art/dreamlike-anime-1.0" else "—Ä–µ–∞–ª–∏–∑–º" if model_id == "SG161222/Realistic_Vision_V5.0_noVAE" else model_id

        bot.send_message(
            call.message.chat.id,
            text=f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\n"
            f"–®–∏—Ä–∏–Ω–∞: {width}\n"
            f"–í—ã—Å–æ—Ç–∞: {height}\n"
            f"–ó–∞–ø—Ä–æ—Å: {user_prompt}\n"
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏: {sampling_steps}\n"
            f"–ú–æ–¥–µ–ª—å: {model_name}"
        )

        pipe = StableDiffusionPipeline.from_pretrained(
            model_id, torch_dtype=torch.float16).to("cuda")
        set_size_and_generate(pipe, call)

    elif call.data == "horizon":
        width = 912
        height = 512
        model_name = "—Ä–∏—Å—É–Ω–æ–∫" if model_id == "dreamlike-art/dreamlike-anime-1.0" else "—Ä–µ–∞–ª–∏–∑–º" if model_id == "SG161222/Realistic_Vision_V5.0_noVAE" else model_id

        bot.send_message(
            call.message.chat.id,
            text=f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\n"
            f"–®–∏—Ä–∏–Ω–∞: {width}\n"
            f"–í—ã—Å–æ—Ç–∞: {height}\n"
            f"–ó–∞–ø—Ä–æ—Å: {user_prompt}\n"
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏: {sampling_steps}\n"
            f"–ú–æ–¥–µ–ª—å: {model_name}"
        )

        pipe = StableDiffusionPipeline.from_pretrained(
            model_id, torch_dtype=torch.float16).to("cuda")
        set_size_and_generate(pipe, call)

    elif call.data == "square":
        width = 512
        height = 512
        model_name = "—Ä–∏—Å—É–Ω–æ–∫" if model_id == "dreamlike-art/dreamlike-anime-1.0" else "—Ä–µ–∞–ª–∏–∑–º" if model_id == "SG161222/Realistic_Vision_V5.0_noVAE" else model_id

        bot.send_message(
            call.message.chat.id,
            text=f"–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –ø—Ä–æ–∏—Å—Ö–æ–¥–∏—Ç –ø–æ –¥–∞–Ω–Ω—ã–º –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º:\n"
            f"–®–∏—Ä–∏–Ω–∞: {width}\n"
            f"–í—ã—Å–æ—Ç–∞: {height}\n"
            f"–ó–∞–ø—Ä–æ—Å: {user_prompt}\n"
            f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —à–∞–≥–æ–≤ –ø—Ä–æ—Ä–∞–±–æ—Ç–∫–∏: {sampling_steps}\n"
            f"–ú–æ–¥–µ–ª—å: {model_name}"
        )

        pipe = StableDiffusionPipeline.from_pretrained(
            model_id, torch_dtype=torch.float16).to("cuda")
        set_size_and_generate(pipe, call)


def get_prompt(message):
    global user_prompt
    user_prompt = message.text.strip()

    if not re.match(r'^[A-Za-z ]+$', user_prompt):
        bot.send_message(
            message.chat.id, "–ü–æ–≤—Ç–æ—Ä–∏—Ç–µ –∑–∞–ø—Ä–æ—Å, –∏—Å–ø–æ–ª—å–∑—É—è —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã –ª–∞—Ç–∏–Ω—Å–∫–æ–≥–æ –∞–ª—Ñ–∞–≤–∏—Ç–∞")
        bot.register_next_step_handler(message, get_prompt)
    else:
        sampling_steps_message(message)


def sampling_steps_message(message):
    markup = types.InlineKeyboardMarkup()

    btn1 = types.InlineKeyboardButton(
        text="20",
        callback_data="20"
    )

    btn2 = types.InlineKeyboardButton(
        text="50",
        callback_data="50"
    )

    btn3 = types.InlineKeyboardButton(
        text="75",
        callback_data="75"
    )

    btn4 = types.InlineKeyboardButton(
        text="100",
        callback_data="100"
    )

    markup.add(btn1)
    markup.add(btn2)
    markup.add(btn3)
    markup.add(btn4)

    bot.send_message(message.chat.id,
                     text=messages[2], reply_markup=markup)


def scale(call):
    markup = types.InlineKeyboardMarkup()

    btn1 = types.InlineKeyboardButton(
        text="‚ÜïÔ∏è –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω–æ",
        callback_data="vert"
    )
    btn2 = types.InlineKeyboardButton(
        text="‚ÜîÔ∏è –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω–æ",
        callback_data="horizon"
    )
    btn3 = types.InlineKeyboardButton(
        text="‚èπÔ∏è –ö–≤–∞–¥—Ä–∞—Ç",
        callback_data="square"
    )

    markup.add(btn1)
    markup.add(btn2)
    markup.add(btn3)

    bot.send_message(call.from_user.id, text=messages[3], reply_markup=markup)


def set_size_and_generate(pipe, call):
    global width, height

    if call.data == "vert":
        width, height = 512, 912

    elif call.data == "horizon":
        width, height = 912, 512

    elif call.data == "square":
        width, height = 512, 512

    request_queue.put((pipe, user_prompt, height, width, sampling_steps, call))

    if not processing_queue:
        process_queue()


def process_queue():
    global processing_queue
    if not processing_queue and not request_queue.empty():
        processing_queue = True
        pipe, user_prompt, height, width, sampling_steps, call = request_queue.get()
        threading.Thread(target=generate_image_from_text, args=(
            pipe, user_prompt, height, width, sampling_steps, call)).start()


def generate_image_from_text(pipe, user_prompt, height, width, sampling_steps, call):
    global processing_queue

    output_dir = r"C:\\Users\\Mari\\Downloads\\text2art\\outputs"
    save_path = os.path.join(output_dir, f"{user_prompt}.png")

    bot.send_message(call.message.chat.id, "–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è...")

    with torch.amp.autocast(device_type="cuda"):
        image = pipe(
            user_prompt, num_inference_steps=sampling_steps, width=width, height=height).images[0]
    image.save(save_path)
    with open(save_path, "rb") as photo:
        bot.send_photo(call.message.chat.id, photo)

    time.sleep(10)
    torch.cuda.empty_cache()

    processing_queue = False
    process_queue()


bot.polling(none_stop=True)

